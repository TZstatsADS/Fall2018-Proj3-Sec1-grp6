### Input: a path for low-resolution images + a path for high-resolution images
###        + number of points sampled from each LR image
### Output: an .RData file contains processed features and responses for the images
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
### read LR/HR image pairs
for(i in 1:n_files){
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgLR <- as.array(imgLR)
imgHR <- as.array(imgHR)
### step 1. sample n_points from imgLR
dimLR <- dim(imgLR)
select = sample(dimLR[1] * dimLR[2], n_points)
select_row <- (select - 1)%%dimLR[1] + 1
select_col <- (select - 1)%/%dimLR[1] + 1
### step 2. for each sampled point in imgLR
### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for(j in 1:3){
pad <- cbind(0, imgLR[,,j], 0)
pad <- rbind(0, pad, 0)
pad_central <- pad[cbind(select_row +1, select_col+1)]
featMat[(i-1)*n_points + 1:n_points, 1, j] <- pad[cbind(select_row, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 2, j] <- pad[cbind(select_row, select_col + 1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 3, j] <- pad[cbind(select_row, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 4, j] <- pad[cbind(select_row +1, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 5, j] <- pad[cbind(select_row +2, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 6, j] <- pad[cbind(select_row+2, select_col+1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 7, j] <- pad[cbind(select_row+2, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 8, j] <- pad[cbind(select_row+1, select_col)]-pad_central
channelHR <- imgHR[,,j]
labMat[(i-1)*n_points + 1:n_points, 1, j] <- channelHR[cbind(select_row*2-1, select_col*2 -1)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 2, j] <- channelHR[cbind(select_row*2-1, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 3, j] <- channelHR[cbind(select_row*2, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 4, j] <- channelHR[cbind(select_row*2, select_col*2 -1)]-pad_central
}
### step 2.2. save the corresponding 4 sub-pixels of imgHR in labMat
### step 3. repeat above for three channels
}
return(list(feature = featMat, label =labMat ))
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
# entire_dir <- "./data/train_set/"
# entire_LR_dir <- paste(train_dir, "LR/", sep="")
# entire_HR_dir <- paste(train_dir, "HR/", sep="")
# #
# #
# lengthvec <- 1:length(list.files(entire_LR_dir))
# testingindex <- sample(lengthvec, 0.2 * length(lengthvec))
# trainingindex <- lengthvec[-testingindex]
# setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# testingfilesLR <- paste0(entire_LR_dir ,  "img_", sprintf("%04d", testingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/test/LR"
# file.copy(testingfilesLR, new.folder)
#
# testingfilesHR <- paste0(entire_HR_dir ,  "img_", sprintf("%04d", testingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/test/HR"
# file.copy(testingfilesHR, new.folder)
#
# trainingfilesLR <- paste0(entire_LR_dir ,  "img_", sprintf("%04d", trainingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/train/LR"
# file.copy(testingfilesLR, new.folder)
#
# trainingfilesHR <- paste0(entire_HR_dir ,  "img_", sprintf("%04d", trainingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/train/HR"
# file.copy(testingfilesHR, new.folder)
train_dir <- "./data/train/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- list(depth = c(3, 11), n.trees = c(150, 200))
model_values <- expand.grid(depth = c(3, 11), n.trees = c(150, 200))
model_labels = paste("GBM with depth =", model_values)
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
feature <- function(LR_dir, HR_dir, n_points=10){
### Construct process features for training images (LR/HR pairs)
### Input: a path for low-resolution images + a path for high-resolution images
###        + number of points sampled from each LR image
### Output: an .RData file contains processed features and responses for the images
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
### read LR/HR image pairs
for(i in 1:n_files){
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgLR <- as.array(imgLR)
imgHR <- as.array(imgHR)
### step 1. sample n_points from imgLR
dimLR <- dim(imgLR)
select = sample(dimLR[1] * dimLR[2], n_points)
select_row <- (select - 1)%%dimLR[1] + 1
select_col <- (select - 1)%/%dimLR[1] + 1
### step 2. for each sampled point in imgLR
### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for(j in 1:3){
pad <- cbind(0, imgLR[,,j], 0)
pad <- rbind(0, pad, 0)
pad_central <- pad[cbind(select_row +1, select_col+1)]
featMat[(i-1)*n_points + 1:n_points, 1, j] <- pad[cbind(select_row, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 2, j] <- pad[cbind(select_row, select_col + 1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 3, j] <- pad[cbind(select_row, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 4, j] <- pad[cbind(select_row +1, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 5, j] <- pad[cbind(select_row +2, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 6, j] <- pad[cbind(select_row+2, select_col+1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 7, j] <- pad[cbind(select_row+2, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 8, j] <- pad[cbind(select_row+1, select_col)]-pad_central
channelHR <- imgHR[,,j]
labMat[(i-1)*n_points + 1:n_points, 1, j] <- channelHR[cbind(select_row*2-1, select_col*2 -1)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 2, j] <- channelHR[cbind(select_row*2-1, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 3, j] <- channelHR[cbind(select_row*2, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 4, j] <- channelHR[cbind(select_row*2, select_col*2 -1)]-pad_central
}
### step 2.2. save the corresponding 4 sub-pixels of imgHR in labMat
### step 3. repeat above for three channels
}
return(list(feature = featMat, label =labMat ))
}
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
feature(train_LR_dir, train_HR_dir)
train_LR_dir
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
# entire_dir <- "./data/train_set/"
# entire_LR_dir <- paste(train_dir, "LR/", sep="")
# entire_HR_dir <- paste(train_dir, "HR/", sep="")
# #
# #
# lengthvec <- 1:length(list.files(entire_LR_dir))
# testingindex <- sample(lengthvec, 0.2 * length(lengthvec))
# trainingindex <- lengthvec[-testingindex]
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
# entire_dir <- "./data/train_set/"
# entire_LR_dir <- paste(train_dir, "LR/", sep="")
# entire_HR_dir <- paste(train_dir, "HR/", sep="")
# #
# #
# lengthvec <- 1:length(list.files(entire_LR_dir))
# testingindex <- sample(lengthvec, 0.2 * length(lengthvec))
# trainingindex <- lengthvec[-testingindex]
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- list(depth = c(3, 11), n.trees = c(150, 200))
model_values <- expand.grid(depth = c(3, 11), n.trees = c(150, 200))
model_labels = paste("GBM with depth =", model_values)
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
a <- matrix(seq(1:24), ncol = 4)
a
a <- c(1,2,3)
a
duplicate(a,2)
duplicated(a,2)
replicate(a,2)
pad[cbind(pixels_row +1, pixels_col+1)]
a <- c(1,2,3)
rep(a,2)
a
matrix(rep(pad[cbind(pixels_row +1, pixels_col+1)],4), ncol = 4)
matrix(rep(a,3),ncol=3)
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- list(depth = c(3, 11), n.trees = c(150, 200))
model_values <- expand.grid(depth = c(3, 11), n.trees = c(150, 200))
model_labels = paste("GBM with depth =", model_values)
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
cv.function <- function(X.train, y.train, modelvalues, K){
n <- dim(y.train)[1]
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i, ,]
train.label <- y.train[s != i, ,]
test.data <- X.train[s == i, ,]
test.label <- y.train[s == i, ,]
#par <- list(depth=d)
fit <- train(train.data, train.label, modelvalues)
pred <- test(fit, test.data)$numericpred
cv.error[i] <- mean((pred - test.label)^2)
}
return(c(mean(cv.error),sd(cv.error)))
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
pred
cv.function <- function(X.train, y.train, modelvalues, K){
n <- dim(y.train)[1]
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i, ,]
train.label <- y.train[s != i, ,]
test.data <- X.train[s == i, ,]
test.label <- y.train[s == i, ,]
#par <- list(depth=d)
fit <- train(train.data, train.label, modelvalues)
pred <- test(fit, test.data)
pred <- pred$numericpred
cv.error[i] <- mean((pred - test.label)^2)
}
return(c(mean(cv.error),sd(cv.error)))
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
cv.function <- function(X.train, y.train, modelvalues, K){
n <- dim(y.train)[1]
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i, ,]
train.label <- y.train[s != i, ,]
test.data <- X.train[s == i, ,]
test.label <- y.train[s == i, ,]
#par <- list(depth=d)
fit <- train(train.data, train.label, modelvalues)
pred <- test(fit, test.data)
pred <- pred$numericpred
cv.error[i] <- mean((pred - test.label)^2)
}
return(c(mean(cv.error),sd(cv.error)))
}
test <- function(modelList, dat_test){
### Fit the classfication model with testing data
### Input:
###  - the fitted classification model list using training data
###  - processed features from testing images
### Output: training model specification
### load libraries
library("gbm")
predArr <- array(NA, c(dim(dat_test)[1], 4, 3))
for (i in 1:12){
fit_train <- modelList[[i]]
### calculate column and channel
c1 <- (i-1) %% 4 + 1
c2 <- (i-c1) %/% 4 + 1
featMat <- dat_test[, , c2]
### make predictions
predArr[, c1, c2] <- predict(fit_train$fit, newdata=featMat,
n.trees=fit_train$iter, type="response")
}
return(list(numericpred = as.numeric(predArr), arraypred = predArr))
}
if(run.cv){
load("../output/err_cv.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
if(!require("xgboost")){
install.packages("xgboost")
}
if(!require("plotly")){
install.packages("plotly")
}
library("EBImage")
library("gbm")
library("xgboost")
library("plotly")
set.seed(2018)
setwd("C:/Users/Yanchen/Desktop/GR5243/Fall2018-Proj3-Sec1-grp6")
set.seed(2018)
setwd("C:/43/paraalel/Fall2018-Proj3-Sec1-grp6")
unlink('main3_cache', recursive = TRUE)
set.seed(2018)
setwd("C:/43/paraalel/Fall2018-Proj3-Sec1-grp6")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
train_dir
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 3  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- expand.grid(depth = c(1,2), n.trees = c(50,100))
model_values_xgb <- expand.grid(max_depth = c(4,6,8), eta = c(0.3,0.5), subsample = c(0.5,0.8), min_child_weight = c(4,6,8))
#setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
library("doParallel")
library("foreach")
source("../lib/train.gbmpar.R")
source("../lib/test.R")
source("../lib/train.xgbpar.R")
source("../lib/cross_validation_gbmpar.R")
if(run.cv){
err_cv.gbmpar <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)) {
cat("k=", k, "\n")
err_cv.gbmpar[k,] <- cv.function.gbmpar(feat_train, label_train, model_values[k, ], K)
}
save(err_cv.gbmpar, file="../output/err_cv.gbmpar.RData")
}
err_cv.gbmpar
print(Sys.time())
if(run.cv){
load("../output/err_cv.gbmpar.RData")
mv <- factor(paste("(", model_values$depth,",", model_values$n.trees, ")"))
plot(err_cv.gbmpar[,1]~mv, xlab="(Interaction Depth, Number of trees)", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.005))
points(err_cv.gbmpar[,1]~mv, col="blue", pch=16)
lines(err_cv.gbmpar[,1]~mv, col="blue")
#arrows(mv,err_cv[,1]-err_cv[,2], mv, err_cv[,1]+err_cv[,2],
#length=0.1, angle=90, code=3)
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv.gbmpar[,1]),]
}
par_best <- list(depth=model_best$depth, n.trees=model_best$n.trees)
par_best
PSNR_gbm <- 20*log10(1) - 10 * log10(err_cv.gbmpar[which.min(err_cv.gbmpar[,1]),1])
PSNR_gbm
tm_train_gbm=NA
tm_train_gbm <- system.time(fit_train.gbmpar <- train.gbmpar(feat_train, label_train, par_best))
save(fit_train.gbmpar, file="../output/fit_train.gbmpar.RData")
source("../lib/cross_validation_xgbpar.R")
if(run.cv){
err_cv.xgbpar <- array(dim=c(nrow(model_values_xgb), 2))
for(k in 1:nrow(model_values_xgb)){
cat("k=", k, "\n")
err_cv.xgbpar[k,] <- cv.function.xgbpar(X.train=feat_train, y.train=label_train, modelvalues=model_values_xgb[k, ], K=K)
}
save(err_cv.xgbpar, file="../output/err_cv.xgbpar.RData")
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
if(!require("xgboost")){
install.packages("xgboost")
}
if(!require("plotly")){
install.packages("plotly")
}
library("EBImage")
library("gbm")
library("xgboost")
library("plotly")
set.seed(2018)
setwd("C:/43/paraalel/Fall2018-Proj3-Sec1-grp6")
