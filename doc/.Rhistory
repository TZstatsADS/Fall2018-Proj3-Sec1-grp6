### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
### read LR/HR image pairs
for(i in 1:3){
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", i), ".jpg"))
pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", i), ".jpg")
featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 8, 3))
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
### step 1. sample n_points from imgLR
dimLR <- dim(imgLR)
pixels = seq(1,dimLR[1] * dimLR[2])
pixels_row <- (pixels - 1)%%dimLR[1] + 1
pixels_col <- (pixels - 1)%/%dimLR[1] + 1
### step 2. for each sampled point in imgLR
### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
n_points <- dim(imgLR)[1] * dim(imgLR)[2]
for(j in 1:3){
pad <- cbind(0, imgLR[,,j], 0)
pad <- rbind(0, pad, 0)
featMat[1:n_points, 1, j] <- pad[cbind(pixels_row, pixels_col)]
featMat[1:n_points, 2, j] <- pad[cbind(pixels_row, pixels_col + 1)]
featMat[1:n_points, 3, j] <- pad[cbind(pixels_row, pixels_col+2)]
featMat[1:n_points, 4, j] <- pad[cbind(pixels_row +1, pixels_col+2)]
featMat[1:n_points, 5, j] <- pad[cbind(pixels_row +2, pixels_col+2)]
featMat[1:n_points, 6, j] <- pad[cbind(pixels_row+2, pixels_col+1)]
featMat[1:n_points, 7, j] <- pad[cbind(pixels_row+2, pixels_col)]
featMat[1:n_points, 8, j] <- pad[cbind(pixels_row+1, pixels_col)]
}
### step 2. apply the modelList over featMat
predMat <- test(modelList, featMat)$arraypred
### step 3. recover high-resolution from predMat and save in HR_dir
imagearray <- array(NA, c((dim(imgLR)[1]*2), (dim(imgLR)[2]*2), 3))
for(k in 1:3){
imagearray[seq(1,dim(imgLR)[1]*2, by =2 ),,k] <-  matrix(c(predMat[,1:2,k]), ncol = dim(imgLR)[2]*2)
imagearray[seq(2,dim(imgLR)[1]*2, by =2 ),,k] <-  matrix(c(predMat[,3:4,k]), ncol = dim(imgLR)[2]*2)
}
imagearray <- Image(imagearray)
colorMode(imagearray) <- Color
writeImage(imagearray, file = paste(HR_dir, i, ".jpg", sep = ""))
}
}
#source("../lib/superResolution.R")
test_dir <- "../data/test_sample/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="../output/fit_train.RData")
tm_test <- system.time(superResolution(LR_dir=test_LR_dir, HR_dir=test_HR_dir, modelList=fit_train))
}
superResolution <- function(LR_dir, HR_dir, modelList){
### Construct high-resolution images from low-resolution images with trained predictor
### Input: a path for low-resolution images + a path for high-resolution images
###        + a list for predictors
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
### read LR/HR image pairs
for(i in 1:3){
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", i), ".jpg"))
pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", i), ".jpg")
featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 8, 3))
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
### step 1. sample n_points from imgLR
dimLR <- dim(imgLR)
pixels = seq(1,dimLR[1] * dimLR[2])
pixels_row <- (pixels - 1)%%dimLR[1] + 1
pixels_col <- (pixels - 1)%/%dimLR[1] + 1
### step 2. for each sampled point in imgLR
### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
n_points <- dim(imgLR)[1] * dim(imgLR)[2]
for(j in 1:3){
pad <- cbind(0, imgLR[,,j], 0)
pad <- rbind(0, pad, 0)
featMat[1:n_points, 1, j] <- pad[cbind(pixels_row, pixels_col)]
featMat[1:n_points, 2, j] <- pad[cbind(pixels_row, pixels_col + 1)]
featMat[1:n_points, 3, j] <- pad[cbind(pixels_row, pixels_col+2)]
featMat[1:n_points, 4, j] <- pad[cbind(pixels_row +1, pixels_col+2)]
featMat[1:n_points, 5, j] <- pad[cbind(pixels_row +2, pixels_col+2)]
featMat[1:n_points, 6, j] <- pad[cbind(pixels_row+2, pixels_col+1)]
featMat[1:n_points, 7, j] <- pad[cbind(pixels_row+2, pixels_col)]
featMat[1:n_points, 8, j] <- pad[cbind(pixels_row+1, pixels_col)]
}
### step 2. apply the modelList over featMat
predMat <- test(modelList, featMat)$arraypred
### step 3. recover high-resolution from predMat and save in HR_dir
imagearray <- array(NA, c((dim(imgLR)[1]*2), (dim(imgLR)[2]*2), 3))
for(k in 1:3){
imagearray[seq(1,dim(imgLR)[1]*2, by =2 ),,k] <-  matrix(c(t(predMat[,1:2,k])), ncol = dim(imgLR)[2]*2)
imagearray[seq(2,dim(imgLR)[1]*2, by =2 ),,k] <-  matrix(c(t(predMat[,3:4,k])), ncol = dim(imgLR)[2]*2)
}
imagearray <- Image(imagearray)
colorMode(imagearray) <- Color
writeImage(imagearray, file = paste(HR_dir, i, ".jpg", sep = ""))
}
}
#source("../lib/superResolution.R")
test_dir <- "../data/test_sample/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="../output/fit_train.RData")
tm_test <- system.time(superResolution(LR_dir=test_LR_dir, HR_dir=test_HR_dir, modelList=fit_train))
}
a
t(a[,1:2])
c(t(a[,1:2]))
feature <- function(LR_dir, HR_dir, n_points=10){
### Construct process features for training images (LR/HR pairs)
### Input: a path for low-resolution images + a path for high-resolution images
###        + number of points sampled from each LR image
### Output: an .RData file contains processed features and responses for the images
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
### read LR/HR image pairs
for(i in 1:n_files){
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgLR <- as.array(imgLR)
imgHR <- as.array(imgHR)
### step 1. sample n_points from imgLR
dimLR <- dim(imgLR)
select = sample(dimLR[1] * dimLR[2], n_points)
select_row <- (select - 1)%%dimLR[1] + 1
select_col <- (select - 1)%/%dimLR[1] + 1
### step 2. for each sampled point in imgLR
### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for(j in 1:3){
pad <- cbind(0, imgLR[,,j], 0)
pad <- rbind(0, pad, 0)
pad_central <- pad[cbind(select_row +1, select_col+1)]
featMat[(i-1)*n_points + 1:n_points, 1, j] <- pad[cbind(select_row, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 2, j] <- pad[cbind(select_row, select_col + 1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 3, j] <- pad[cbind(select_row, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 4, j] <- pad[cbind(select_row +1, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 5, j] <- pad[cbind(select_row +2, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 6, j] <- pad[cbind(select_row+2, select_col+1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 7, j] <- pad[cbind(select_row+2, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 8, j] <- pad[cbind(select_row+1, select_col)]-pad_central
channelHR <- imgHR[,,j]
labMat[(i-1)*n_points + 1:n_points, 1, j] <- channelHR[cbind(select_row*2-1, select_col*2 -1)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 2, j] <- channelHR[cbind(select_row*2-1, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 3, j] <- channelHR[cbind(select_row*2, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 4, j] <- channelHR[cbind(select_row*2, select_col*2 -1)]-pad_central
}
### step 2.2. save the corresponding 4 sub-pixels of imgHR in labMat
### step 3. repeat above for three channels
}
return(list(feature = featMat, label =labMat ))
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
# entire_dir <- "./data/train_set/"
# entire_LR_dir <- paste(train_dir, "LR/", sep="")
# entire_HR_dir <- paste(train_dir, "HR/", sep="")
# #
# #
# lengthvec <- 1:length(list.files(entire_LR_dir))
# testingindex <- sample(lengthvec, 0.2 * length(lengthvec))
# trainingindex <- lengthvec[-testingindex]
# setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# testingfilesLR <- paste0(entire_LR_dir ,  "img_", sprintf("%04d", testingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/test/LR"
# file.copy(testingfilesLR, new.folder)
#
# testingfilesHR <- paste0(entire_HR_dir ,  "img_", sprintf("%04d", testingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/test/HR"
# file.copy(testingfilesHR, new.folder)
#
# trainingfilesLR <- paste0(entire_LR_dir ,  "img_", sprintf("%04d", trainingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/train/LR"
# file.copy(testingfilesLR, new.folder)
#
# trainingfilesHR <- paste0(entire_HR_dir ,  "img_", sprintf("%04d", trainingindex), ".jpg")
# new.folder <- "~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6/data/train/HR"
# file.copy(testingfilesHR, new.folder)
train_dir <- "./data/train/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- list(depth = c(3, 11), n.trees = c(150, 200))
model_values <- expand.grid(depth = c(3, 11), n.trees = c(150, 200))
model_labels = paste("GBM with depth =", model_values)
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
feature <- function(LR_dir, HR_dir, n_points=10){
### Construct process features for training images (LR/HR pairs)
### Input: a path for low-resolution images + a path for high-resolution images
###        + number of points sampled from each LR image
### Output: an .RData file contains processed features and responses for the images
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
### read LR/HR image pairs
for(i in 1:n_files){
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgLR <- as.array(imgLR)
imgHR <- as.array(imgHR)
### step 1. sample n_points from imgLR
dimLR <- dim(imgLR)
select = sample(dimLR[1] * dimLR[2], n_points)
select_row <- (select - 1)%%dimLR[1] + 1
select_col <- (select - 1)%/%dimLR[1] + 1
### step 2. for each sampled point in imgLR
### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
for(j in 1:3){
pad <- cbind(0, imgLR[,,j], 0)
pad <- rbind(0, pad, 0)
pad_central <- pad[cbind(select_row +1, select_col+1)]
featMat[(i-1)*n_points + 1:n_points, 1, j] <- pad[cbind(select_row, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 2, j] <- pad[cbind(select_row, select_col + 1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 3, j] <- pad[cbind(select_row, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 4, j] <- pad[cbind(select_row +1, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 5, j] <- pad[cbind(select_row +2, select_col+2)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 6, j] <- pad[cbind(select_row+2, select_col+1)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 7, j] <- pad[cbind(select_row+2, select_col)]-pad_central
featMat[(i-1)*n_points + 1:n_points, 8, j] <- pad[cbind(select_row+1, select_col)]-pad_central
channelHR <- imgHR[,,j]
labMat[(i-1)*n_points + 1:n_points, 1, j] <- channelHR[cbind(select_row*2-1, select_col*2 -1)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 2, j] <- channelHR[cbind(select_row*2-1, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 3, j] <- channelHR[cbind(select_row*2, select_col*2)]-pad_central
labMat[(i-1)*n_points + 1:n_points, 4, j] <- channelHR[cbind(select_row*2, select_col*2 -1)]-pad_central
}
### step 2.2. save the corresponding 4 sub-pixels of imgHR in labMat
### step 3. repeat above for three channels
}
return(list(feature = featMat, label =labMat ))
}
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
feature(train_LR_dir, train_HR_dir)
train_LR_dir
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
# entire_dir <- "./data/train_set/"
# entire_LR_dir <- paste(train_dir, "LR/", sep="")
# entire_HR_dir <- paste(train_dir, "HR/", sep="")
# #
# #
# lengthvec <- 1:length(list.files(entire_LR_dir))
# testingindex <- sample(lengthvec, 0.2 * length(lengthvec))
# trainingindex <- lengthvec[-testingindex]
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
set.seed(2018)
#setwd("./ads_fall2018_proj3")
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
# entire_dir <- "./data/train_set/"
# entire_LR_dir <- paste(train_dir, "LR/", sep="")
# entire_HR_dir <- paste(train_dir, "HR/", sep="")
# #
# #
# lengthvec <- 1:length(list.files(entire_LR_dir))
# testingindex <- sample(lengthvec, 0.2 * length(lengthvec))
# trainingindex <- lengthvec[-testingindex]
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- list(depth = c(3, 11), n.trees = c(150, 200))
model_values <- expand.grid(depth = c(3, 11), n.trees = c(150, 200))
model_labels = paste("GBM with depth =", model_values)
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
a <- matrix(seq(1:24), ncol = 4)
a
a <- c(1,2,3)
a
duplicate(a,2)
duplicated(a,2)
replicate(a,2)
pad[cbind(pixels_row +1, pixels_col+1)]
a <- c(1,2,3)
rep(a,2)
a
matrix(rep(pad[cbind(pixels_row +1, pixels_col+1)],4), ncol = 4)
matrix(rep(a,3),ncol=3)
train_dir <- "./data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 2  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- list(depth = c(3, 11), n.trees = c(150, 200))
model_values <- expand.grid(depth = c(3, 11), n.trees = c(150, 200))
model_labels = paste("GBM with depth =", model_values)
setwd("~/Documents/GitHub/Fall2018-Proj3-Sec1-grp6")
#source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
cv.function <- function(X.train, y.train, modelvalues, K){
n <- dim(y.train)[1]
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i, ,]
train.label <- y.train[s != i, ,]
test.data <- X.train[s == i, ,]
test.label <- y.train[s == i, ,]
#par <- list(depth=d)
fit <- train(train.data, train.label, modelvalues)
pred <- test(fit, test.data)$numericpred
cv.error[i] <- mean((pred - test.label)^2)
}
return(c(mean(cv.error),sd(cv.error)))
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
pred
cv.function <- function(X.train, y.train, modelvalues, K){
n <- dim(y.train)[1]
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i, ,]
train.label <- y.train[s != i, ,]
test.data <- X.train[s == i, ,]
test.label <- y.train[s == i, ,]
#par <- list(depth=d)
fit <- train(train.data, train.label, modelvalues)
pred <- test(fit, test.data)
pred <- pred$numericpred
cv.error[i] <- mean((pred - test.label)^2)
}
return(c(mean(cv.error),sd(cv.error)))
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(nrow(model_values), 2))
for(k in 1:nrow(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k, ], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
cv.function <- function(X.train, y.train, modelvalues, K){
n <- dim(y.train)[1]
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i, ,]
train.label <- y.train[s != i, ,]
test.data <- X.train[s == i, ,]
test.label <- y.train[s == i, ,]
#par <- list(depth=d)
fit <- train(train.data, train.label, modelvalues)
pred <- test(fit, test.data)
pred <- pred$numericpred
cv.error[i] <- mean((pred - test.label)^2)
}
return(c(mean(cv.error),sd(cv.error)))
}
test <- function(modelList, dat_test){
### Fit the classfication model with testing data
### Input:
###  - the fitted classification model list using training data
###  - processed features from testing images
### Output: training model specification
### load libraries
library("gbm")
predArr <- array(NA, c(dim(dat_test)[1], 4, 3))
for (i in 1:12){
fit_train <- modelList[[i]]
### calculate column and channel
c1 <- (i-1) %% 4 + 1
c2 <- (i-c1) %/% 4 + 1
featMat <- dat_test[, , c2]
### make predictions
predArr[, c1, c2] <- predict(fit_train$fit, newdata=featMat,
n.trees=fit_train$iter, type="response")
}
return(list(numericpred = as.numeric(predArr), arraypred = predArr))
}
if(run.cv){
load("../output/err_cv.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
